import requests
import json
import csv
from datetime import datetime, timedelta
import yaml
import pytz  
import os
import boto3  
from email.mime.multipart import MIMEMultipart
from email.mime.base import MIMEBase
from email import encoders
from email.mime.text import MIMEText
import time
import re

## Script configuration variables

# Defining the API URL and API Key
api_url = "https://services.nvd.nist.gov/rest/json/cves/2.0"
api_key = ''

# Defining the search time delta (number of days to look back)
time_delta = 7

# Defining the timezone for date and time
timezone = "America/Sao_Paulo"

# Debug Mode
debug = False

# Keywords file path
input_csv = "./input.csv"

# Cloud deploy flag
cloud_deploy = False

# List of keywords found in NVD 
keywords_found = []

# Cloud deploy S3 settings
s3_bucket = 'cve.query'
s3_input_csv_key = 'input.csv'

# Email settings
sender_email = 'your-sender-email'
recipient_email = 'your-recipient-email'
aws_region = 'your-aws-region'

## Script configuration variables

def get_cves_for_keyword(keyword):
    """
    Fetches CVEs for a given keyword from the API and saves the results in a JSON file.
    """
    # Query without an api key
    if api_key != "":
        # API Key in the request header
        headers = {
            'apiKey': api_key
        }

        # Sleep time to meet the established limits (https://nvd.nist.gov/developers/start-here)
        sleep_time = 0.6 
    else:
        sleep_time = 6

    # Current date and time
    end_date = datetime.now()

    # Date and time 7 days ago (or as specified by `time_delta`)
    start_date = end_date - timedelta(days=time_delta)

    # Convert the timezone string into a pytz timezone object
    try:
        if timezone.startswith('UTC'):
            tz = pytz.UTC
        else:
            tz = pytz.timezone(timezone)
    except Exception as e:
        print(f"Error with timezone {timezone}: {e}")
        tz = pytz.UTC  # Default to UTC in case of an error

    # Localize the dates to the specified timezone
    end_date = tz.localize(end_date)
    start_date = tz.localize(start_date)

    # Format the dates to the required ISO 8601 format with timezone offset
    end_date_str = end_date.strftime('%Y-%m-%dT%H:%M:%S.%f')[:-3] + end_date.strftime('%z')[:3] + ':' + end_date.strftime('%z')[3:]
    start_date_str = start_date.strftime('%Y-%m-%dT%H:%M:%S.%f')[:-3] + start_date.strftime('%z')[:3] + ':' + start_date.strftime('%z')[3:]

    # Debug: Check the formatted dates
    if debug:
        print("Start Date:", start_date_str)
        print("End Date:", end_date_str)

    params = {
        'pubStartDate': start_date_str,
        'pubEndDate': end_date_str,
        'keywordSearch': keyword,
        'resultsPerPage': 20,
        'startIndex': 0
    }

    # List to hold the CVEs fetched from the API
    cves = []

    # Compile regex pattern for exact keyword match
    keyword_pattern = re.compile(r'\b' + re.escape(keyword) + r'\b', re.IGNORECASE)

    # Fetch results and paginate if necessary
    while True:

        # Query without an api key
        if api_key != "":
            response = requests.get(api_url, headers=headers, params=params)
        else:
            response = requests.get(api_url, params=params)

        # Sleep time to meet limits
        time.sleep(sleep_time)
        
        # Check the status code of the response
        if response.status_code != 200:
            print(f"Error {response.status_code}: {response.content}")
            break

        try:
            # Convert the JSON response to a dictionary
            data = response.json()
            
            # Debug: Check the structure of the JSON response
            if debug:
                print("Data received from API:", json.dumps(data, indent=2))

            # Append the 'cve' information from 'vulnerabilities' to the list
            for item in data.get('vulnerabilities', []):
                cve_info = item.get('cve', {})
                # Filter results by keyword pattern
                if keyword_pattern.search(json.dumps(cve_info)):
                    cves.append(cve_info)

            # Debug: Check the number of CVEs fetched so far
            if debug:
                print(f"Fetched {len(cves)} CVEs so far")

        except Exception as error:
            print(f"Error parsing JSON: {error}")
            break

        # Pagination: Check if there are more results to fetch
        total_results = data.get('totalResults', 0)
        if params['startIndex'] + params['resultsPerPage'] >= total_results:
            break

        # Move to the next page of results
        params['startIndex'] += params['resultsPerPage']

    # Generate the filename with the current date in YYYYMMDD format
    current_date_str = end_date.strftime('%Y%m%d')
    filename = f'cves_{keyword}_{current_date_str}.json'

    # Save the CVEs to a JSON file if there are any results
    if cves:
        if cloud_deploy:
            filename = f'/tmp/{filename}'  # AWS Lambda's writeable directory

            # Register the keyword of found CVE to compose the email with results
            keywords_found.append(keyword)

        with open(filename, 'w', encoding='utf-8') as json_file:
            json.dump(cves, json_file, ensure_ascii=False, indent=4)
            
        print(f"Saved {len(cves)} CVEs to {filename}")

    else:
        print(f"No CVEs found for keyword: {keyword}")

def send_email_with_attachment():
    """
    Sends an email with the files generated by get_cves_for_keyword as an attachment using Amazon SES.
    """    

    # AWS SES client
    client = boto3.client('ses', region_name=aws_region)

    # Directory with CVEs json files
    directory = "/tmp"

    # Message data
    msg = MIMEMultipart()
    msg['Subject'] = f"CVEs query results"
    msg['From'] = sender_email
    msg['To'] = recipient_email

    # Define the email body
    email_body = f"Please find attached the CVEs found for keywords:"
    
    # Keyword list
    for keyword in keywords_found:
        email_body = email_body + ", " + keyword

    # Add the text part to the parent container directly
    textpart = MIMEText(email_body, 'plain')
    msg.attach(textpart)

    # Iterate through all files in the directory and attach them to the email
    for filename in os.listdir(directory):
        if filename not in input_csv:
            file_path = os.path.join(directory, filename)
            if os.path.isfile(file_path):
                with open(file_path, 'rb') as file:
                    # File reading 
                    file_data = file.read()

                    # Attach the file
                    part = MIMEBase('application', "octet-stream")
                    part.set_payload(file_data)
                    encoders.encode_base64(part)
                    part.add_header('Content-Disposition', f'attachment; filename="{os.path.basename(filename)}"')
                    msg.attach(part)       

    # Send the email
    try:
        response = client.send_raw_email(
            Source=sender_email,
            Destinations=[recipient_email],
            RawMessage={
                'Data': msg.as_string()
            }
        )
        print("Email sent! Message ID:", response['MessageId'])
    except Exception as e:
        print("Error sending email:", e)
      
def main():
    """
    Main function to load settings, read keywords from CSV, and fetch CVEs for each keyword.
    """

    # Global variable
    global input_csv

    # List to store keywords from the CSV
    keywords = []
   
    # Keyword file download in cloud deploy
    if cloud_deploy:

        # Define paths for the downloaded files in the Lambda environment
        input_csv = '/tmp/' + input_csv

        s3 = boto3.client('s3')
        s3.download_file(s3_bucket, s3_input_csv_key, input_csv)
    
    try:

        # Open the CSV file containing the keywords
        with open(input_csv, mode='r', encoding='utf-8') as file:
            csv_reader = csv.DictReader(file)
            
            # Iterate over the rows in the CSV and collect the keywords
            for row in csv_reader:
                if 'keyword' in row:
                    keywords.append(row['keyword'])
                else:
                    print("The CSV file does not contain a 'keyword' column.")

        # Perform the CVE search for each keyword
        for keyword in keywords:
            get_cves_for_keyword(keyword)
    
    except Exception as e:
        print("Error handling keyword csv file:", e)

    # Send email with CVEs json files
    if cloud_deploy:
        send_email_with_attachment()

def lambda_handler(event, context):
    """
    AWS Lambda handler function.
    """
    # Call the main function with the updated settings
    main()
    
    return {
        'statusCode': 200,
        'body': json.dumps('CVE search completed')
    }

if __name__ == '__main__':
    main()  # Run the main function with the path to the settings YAML file
